{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Work: Classification for facial beauty detection\n",
    "## Part 1: Creating a simple beauty detector from an existing dataset\n",
    "\n",
    "Please keep in mind that this is a not so ethical use of Machine Learning.  \n",
    "With great technological power comes great responsabilities.  \n",
    "Please students, don't be evil.\n",
    "\n",
    "_Hints: https://github.com/ustcqidi/BeautyPredict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Get the data\n",
    "- Get the dataset from here: https://github.com/HCIILAB/SCUT-FBP5500-Database-Release\n",
    "- Put it in the datasets folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path = os.path.abspath('C:/poubelle/MECA653')  # Specific to Polytech Annecy\n",
    "if os.path.isdir(local_path):\n",
    "    print('Will use a local path on Polytech Annecy desktop', local_path)\n",
    "else:\n",
    "    local_path = None\n",
    "\n",
    "dataset_path = os.path.relpath('datasets/SCUT-FBP5500_v2')\n",
    "if local_path:\n",
    "    dataset_path = os.path.join(local_path, dataset_path)\n",
    "\n",
    "csv_file_path = os.path.join(dataset_path, 'train_test_files', 'All_labels.txt')\n",
    "images_path = os.path.join(dataset_path, 'Images')\n",
    "\n",
    "models_path = os.path.relpath('models')\n",
    "if local_path:\n",
    "    models_path = os.path.join(local_path, models_path)\n",
    "\n",
    "print(\"local_path:\", local_path)\n",
    "print(\"dataset_path:\", dataset_path)\n",
    "print(\"csv_file_path:\", csv_file_path)\n",
    "print(\"images_path:\", images_path)\n",
    "print(\"models_path:\", models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean rate by the 60th raters\n",
    "df = 'add your code to read the csv with pandas (columns names=[\"filename\", \"rating\"] and the separator is a space))'\n",
    "\n",
    "# Check the 5th first row\n",
    "# df.head()\n",
    "\n",
    "# Describe the dataset\n",
    "# df.describe()\n",
    "\n",
    "# Rates histogram\n",
    "# df.rating.hist(bins=30, density=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2- Configure Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip3 install tensorflow==1.15.2\n",
    "# pip3 install keras\n",
    "# pip3 install Pillow\n",
    "\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create a batch generator\n",
    "img_size = 224\n",
    "batch_size = 32  # 64\n",
    "validation_split = 0.2\n",
    "training_steps_per_epoch = (len(df) * (1 - validation_split)) // batch_size\n",
    "validation_steps = (len(df) * validation_split) // batch_size\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # This is what modify image color for ImageNet normalization\n",
    "    # rescale=1/255.0,  # not used because of preprocessing_function\n",
    "    validation_split=validation_split\n",
    "    )\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(     \n",
    "    subset='training',\n",
    "    dataframe=df,  \n",
    "    directory=images_path,\n",
    "    x_col='filename', # name of col in data frame that contains file names\n",
    "    y_col='rating', # name of col with labels\n",
    "    has_ext=True, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode='other',  # : regression, 'categorical' for classification task\n",
    "    interpolation='nearest')  # 'bilinear'\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(     \n",
    "    subset='validation',\n",
    "    dataframe=df,  \n",
    "    directory=images_path,\n",
    "    x_col='filename', # name of col in data frame that contains file names\n",
    "    y_col='rating', # name of col with labels\n",
    "    has_ext=True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    target_size=(img_size, img_size),\n",
    "    class_mode='other',  # : regression, 'categorical' for classification task\n",
    "    interpolation='nearest')  # 'bilinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset\n",
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=150)\n",
    "plt.subplots_adjust(bottom=0, left=.01, right=1.2, top=0.9, hspace=.01)\n",
    "for i, (image, label) in enumerate(zip(x_batch[:32], y_batch[:32])):\n",
    "    plt.subplot(4, 8, i + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.title('N°%i | Beauty: %.2f' % (i, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create your neural network\n",
    "We will use transfer learning.  \n",
    "We use a pre-trained model with no last layer.  \n",
    "We add our custom last layer on the model.  \n",
    "Then we train only train our last layer.  \n",
    "It is important to choose a good last layer architecture, you should try some or use AutoML (bayesian/genetic search).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "# model.add(ResNet50(include_top = False, pooling = 'avg', weights='imagenet'))\n",
    "\n",
    "model.add('add a ResNet50 or a MobileNetV2 network to your model with include_top=False')\n",
    "\n",
    "# 2nd layer as Dense with ReLu\n",
    "model.add('add a first Dense layer')\n",
    "\n",
    "# 3rd layer as Dense for regression\n",
    "model.add('add a second Dense layer if you want')\n",
    "\n",
    "# Say not to train first layer (ResNet) model as it is already trained\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "# adam = Adam()  # lr=1e-3, decay=1e-3/200\n",
    "\n",
    "model.compile(optimizer=sgd, loss='mean_absolute_error')  # 'mean_absolute_percentage_error', 'mean_squared_error', 'kullback_leibler_divergence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "n_workers = multiprocessing.cpu_count() - 2\n",
    "print('We have %d physical CPUs. We will use %d workers for preprocessing.' % (multiprocessing.cpu_count(), n_workers))\n",
    "\n",
    "n_epochs = 100  # You can reduce the number of epoch to train faster\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=training_steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    validation_data=validation_generator,\n",
    "    max_queue_size=30,  # default=10\n",
    "    workers=n_workers,  # default=1\n",
    "    use_multiprocessing=False  # default=False\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model.save(os.path.join(models_path, 'beauty_model_untuned.h5'))  # creates a HDF5 file of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(15, 8)) \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('Model loss during training')  \n",
    "plt.ylabel('Mean Absolute Error')  \n",
    "plt.xlabel('Epoch')  \n",
    "plt.legend(['train', 'validation']) \n",
    "\n",
    "plt.show()\n",
    "# plt.savefig('performance.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Validate the trained model performance\n",
    "We will use the model to predict the score on every image of the __validation__ dataset.  \n",
    "Then we will compute some statistics to study the model performance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the train model for all images in validation\n",
    "y_predicted = model.predict_generator(validation_generator, steps = validation_steps).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the reference (true) values\n",
    "y_test = validation_generator.labels[:y_predicted.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some performance metrics\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_predicted))\n",
    "print('Root Mean Squared Error: %.3f' % rmse)\n",
    "\n",
    "mse = mean_absolute_error(y_test, y_predicted)\n",
    "print('Mean Absolute Error: %.3f' % mse)\n",
    "\n",
    "r, p_value = pearsonr(y_test, y_predicted.reshape(-1))\n",
    "print(\"Pearson's Correlation Coefficient: %.3f\" % r)\n",
    "print('Two-tailed p-value: %.3f' % p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5- Use the model to predict on any image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import PIL\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from ipywidgets import interact, interact_manual\n",
    "except ImportError:\n",
    "    raise ImportError('ipywidgets is not installed.', 'Check the comment to install on current env.')\n",
    "# How to install ipywidgets in current Jupyter env\n",
    "#   Execute in a Jupyter field:\n",
    "#     import sys\n",
    "#     !{sys.executable} -m pip install ipywidgets\n",
    "#\n",
    "#   Then run in CLI:\n",
    "#     $jupyter nbextension enable --py widgetsnbextension  # for Jupyter Notebook\n",
    "#     $jupyter labextension install @jupyter-widgets/jupyterlab-manager  # for Jupyter Lab\n",
    "\n",
    "# Define paths\n",
    "local_path = os.path.abspath('C:/poubelle/MECA653')  # Specific to Polytech Annecy\n",
    "if not os.path.isdir(local_path):\n",
    "    local_path = None\n",
    "\n",
    "dataset_path = os.path.relpath('datasets/SCUT-FBP5500_v2')\n",
    "if local_path:\n",
    "    dataset_path = os.path.join(local_path, dataset_path)\n",
    "\n",
    "csv_file_path = os.path.join(dataset_path, 'train_test_files', 'All_labels.txt')\n",
    "df = pd.read_csv(csv_file_path, header=None, names=['filename', 'rating'], sep=' ')\n",
    "images_path = os.path.join(dataset_path, 'Images')\n",
    "\n",
    "models_path = os.path.relpath('models')\n",
    "if local_path:\n",
    "    models_path = os.path.join(local_path, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "model = load_model(os.path.join(models_path, 'beauty_model_untuned.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact  # Create an ipywidgets selector\n",
    "def show_images(file=os.listdir(images_path)):\n",
    "    # Preprocess the image as a model input\n",
    "    img_size = 224\n",
    "    img = image.load_img(os.path.join(images_path, file), target_size = (img_size, img_size))\n",
    "    img = image.img_to_array(img)\n",
    "    img = preprocess_input(img)\n",
    "    img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "    reference =  df[df['filename'] == file].rating.values[0]  # Get the reference from the dataset\n",
    "    prediction = model.predict(img)[0][0]  # Use da model\n",
    "\n",
    "    display(Image(os.path.join(images_path, file)))  # Display the image\n",
    "\n",
    "    print('Reference beauty:', reference)\n",
    "    print('Predicted beauty:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact\n",
    "def predict_from_url(URL='https://upload.wikimedia.org/wikipedia/commons/c/c0/Nicolas_Cage_Deauville_2013.jpg'):\n",
    "    with urllib.request.urlopen(URL) as url:  # Download an image from an URL in RAM memory\n",
    "        img_size = 224\n",
    "        img = image.load_img(BytesIO(url.read()), target_size=(img_size, img_size))\n",
    "        display(img)  # Display the image\n",
    "\n",
    "        # Preprocess image\n",
    "        img = image.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        img = np.expand_dims(img, axis = 0)\n",
    "\n",
    "        prediction = model.predict(img)[0][0]  # Use da model\n",
    "        print('Predicted beauty:', prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Predict beauty in real time from a webcam¶\n",
    "\n",
    "Hints to fix jupyterlab IPython plugins:\n",
    "```bash\n",
    "pip3 install ipywidgets -U\n",
    "jupyter nbextension enable --py widgetsnbextension\n",
    "jupyter labextension install @jupyter-widgets/jupyterlab-manager\n",
    "jupyter lab clean\n",
    "jupyter lab build\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "local_path = os.path.abspath('C:/poubelle/MECA653')  # Specific to Polytech Annecy\n",
    "if os.path.isdir(local_path):\n",
    "    print('Will use a local path on Polytech Annecy desktop', local_path)\n",
    "else:\n",
    "    local_path = None\n",
    "models_path = os.path.relpath('models')\n",
    "if local_path:\n",
    "    models_path = os.path.join(local_path, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(os.path.join(models_path, 'beauty_model_untuned.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "import PIL.Image\n",
    "from io import BytesIO\n",
    "import IPython.display\n",
    "from matplotlib import pyplot as plt\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple live stream with face beauty ranking using Deep Transfer Learning\n",
    "\n",
    "#Use 'jpeg' instead of 'png' (~5 times faster)\n",
    "def array_to_image(a, fmt='jpeg'):\n",
    "    #Create binary stream object\n",
    "    f = BytesIO()\n",
    "\n",
    "    #Convert array to binary stream object\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "\n",
    "    return IPython.display.Image(data=f.getvalue())\n",
    "\n",
    "# Load a VideoCapture from a webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('Could not open video device 0.')\n",
    "    print('Will use a video file.')\n",
    "    cap = cv2.VideoCapture(os.path.abspath(os.path.join(local_path, 'datasets/head-pose-face-detection-female.mp4')))\n",
    "\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 320)  # 640\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 240)  # 480\n",
    "\n",
    "print('Webcam frame size: %d x %d' % (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "\n",
    "\n",
    "d = IPython.display.display(\"\", display_id=1)\n",
    "d_fps = IPython.display.display(\"\", display_id=2)\n",
    "\n",
    "# Display and face detect & ranking loop\n",
    "img_size = 224\n",
    "crop_box_add = 30\n",
    "debounce_detector = 0  # debouncer to do the detection only every 10 frames\n",
    "debounce_detector_frames_nb = 10  # debouncer to do the detection only every 10 frames, should be > 0\n",
    "\n",
    "while(True):\n",
    "    try:\n",
    "        # Capture frame-by-frame\n",
    "        t1 = time.time()\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.resize(frame, (img_size, img_size))\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = cv2.flip(frame, 1)\n",
    "\n",
    "        if debounce_detector <= 0:  # Compute face & beauty every 10 frames\n",
    "            debounce_detector = debounce_detector_frames_nb\n",
    "\n",
    "            cropped_images = np.array(cropped_images)\n",
    "            preprocessed_image = preprocess_input(frame)\n",
    "            preprocessed_image = np.expand_dims(preprocessed_image, axis = 0)\n",
    "            y_pred = model.predict(preprocessed_image)[0][0]\n",
    "\n",
    "        # Scores\n",
    "        cv2.putText(frame, str('%.2f' % (y_pred)), (10, img_size - 10), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the video output\n",
    "        image = array_to_image(frame)\n",
    "        d.update(image)\n",
    "        s = f\"\"\"{int(1 / (time.time() - t1))} FPS\"\"\"\n",
    "        d_fps.update( IPython.display.HTML(s) )\n",
    "\n",
    "        debounce_detector = debounce_detector - 1\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print()\n",
    "        cap.release()\n",
    "        IPython.display.clear_output()\n",
    "        print (\"Stream stopped\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Rank scaling analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import MinMaxScaler, QuantileTransformer\n",
    "\n",
    "# Define scalers\n",
    "min_max_scaler = MinMaxScaler(feature_range=(0, 5), copy=True)\n",
    "quantile_normal_scaler = QuantileTransformer(output_distribution='normal', copy=True)\n",
    "quantile_uniform_scaler = QuantileTransformer(output_distribution='uniform', copy=True)\n",
    "\n",
    "# Fit\n",
    "min_max_scaler.fit(df['rating'].values.reshape(-1, 1))\n",
    "quantile_normal_scaler.fit(df['rating'].values.reshape(-1, 1))\n",
    "quantile_uniform_scaler.fit(df['rating'].values.reshape(-1, 1))\n",
    "\n",
    "# Plots\n",
    "n_bins = 100\n",
    "f, (ax0, ax1, ax2, ax3) = plt.subplots(ncols=1, nrows=4, sharex=True, figsize=(18, 8))\n",
    "\n",
    "x = df['rating'].values\n",
    "n, bins, patches = ax0.hist(x, bins=n_bins, density=True)\n",
    "(mu, sigma) = norm.fit(x)\n",
    "y = norm.pdf(bins, mu, sigma)\n",
    "ax0.plot(bins, y, 'r--', linewidth=1)\n",
    "ax0.set_xlim([0, 5])\n",
    "ax0.set_ylabel('Probability')\n",
    "ax0.set_title('Original rank')\n",
    "\n",
    "x = min_max_scaler.transform(df['rating'].values.reshape(-1, 1))\n",
    "n, bins, patches = ax1.hist(x, bins=n_bins, density=True)\n",
    "(mu, sigma) = norm.fit(x)\n",
    "y = norm.pdf(bins, mu, sigma)\n",
    "ax1.plot(bins, y, 'r--', linewidth=1)\n",
    "ax1.set_ylabel('Probability')\n",
    "ax1.set_title('Min Max')\n",
    "\n",
    "x = quantile_normal_scaler.transform(df['rating'].values.reshape(-1, 1))\n",
    "x -= x.min()\n",
    "x /= x.max()\n",
    "x *= 5.0\n",
    "n, bins, patches = ax2.hist(x, bins=n_bins, density=True)\n",
    "(mu, sigma) = norm.fit(x)\n",
    "y = norm.pdf(bins, mu, sigma)\n",
    "ax2.plot(bins, y, 'r--', linewidth=1)\n",
    "ax2.set_ylabel('Probability')\n",
    "ax2.set_title('Quantile Normal')\n",
    "\n",
    "x = quantile_uniform_scaler.transform(df['rating'].values.reshape(-1, 1))\n",
    "x *= 5.0\n",
    "n, bins, patches = ax3.hist(x, bins=n_bins, density=True)\n",
    "(mu, sigma) = norm.fit(x)\n",
    "y = norm.pdf(bins, mu, sigma)\n",
    "ax3.plot(bins, y, 'r--', linewidth=1)\n",
    "ax3.set_xlabel('Rank')\n",
    "ax3.set_ylabel('Probability')\n",
    "ax3.set_title('Quantile Uniform')\n",
    "\n",
    "f.suptitle('Rank Scaling Analysis', y=0.035)\n",
    "f.tight_layout(rect=[0.05, 0.05, 0.95, 0.95])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
